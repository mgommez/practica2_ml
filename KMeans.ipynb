{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Implementación K-means\n",
    "K-means\n",
    "    Elegir instacias del dataset como centroides iniciales\n",
    "    Distirbuir puntos del dataset a los centroides\n",
    "    Calcular la media de las distancias respecto de los puntos\n",
    "    Se recalculaba el centroide \n",
    "    Repetir hasta que no haya cambios\n",
    "    \n",
    "Estaría bien usar la misma interfaz que sckikit learn\n",
    "Kmeans = Kmeans(K=5)\n",
    "Kmeans.fit(X)\n",
    "Kmeans.predict(X)\n",
    "\n",
    "Tenemos un conjunto de datos, eliges el numero de clusters (n_clusters), asignas los centroides a unos datos aleatoriamente (init -> puntos aleatorios del dataset), y después asignas los datos a los clusters (asignar_clusters). Después hay que computar los nuevos centroides en un bucle y volver a asignar los clusters hasta que se cumpla la condición de parada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T08:04:58.790970400Z",
     "start_time": "2024-05-08T08:04:30.508167500Z"
    }
   },
   "outputs": [],
   "source": [
    "# con la librería de SciKit Learn:\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans()\n",
    "#kmeans.fit(X)\n",
    "#kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import dist\n",
    "import statistics as s\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x, y = make_blobs()\n",
    "print(x.shape[1])\n",
    "print(\"EQUIS: \\n\", x)\n",
    "print(\"Y: \\n\", y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class KMeans_Ours():\n",
    "    def __init__(self, n_clusters=8, max_iter=100, random_state=55):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.iter = 0\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.X= []\n",
    "        \n",
    "        self._centroids= []\n",
    "        self._inertia=[]\n",
    "        self._labels=[]\n",
    "        self.history = {'iteration': [],\n",
    "                        'centroids':  [],  \n",
    "                        'labels' : [],\n",
    "                        'inertia':  []\n",
    "                        }\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Este método entrena el modelo con el dataset proporcionado, aplicando el algoritmo de asignación de centroides\"\"\"\n",
    "        self.X = X\n",
    "        self._assign_centroids()\n",
    "        self._assign_labels()\n",
    "        # print(\"centroides iniciales: \", self._centroids)\n",
    "        while not self._stop(): # si se llega a max iter o si centroides no cambian (con último valor de self.history), una u otra\n",
    "            self._add_history_step() \n",
    "            # con esto podemos hacer un gráfico (no se pide pero quedaría rechulón)\n",
    "            \n",
    "            self._update_centroides()\n",
    "            # print(\"history: \", self.history['centroids'][self.iter])\n",
    "            self._assign_labels()\n",
    "            \n",
    "            self.iter += 1\n",
    "            \n",
    "    def return_centroids(self):\n",
    "        return self._centroids\n",
    "    \n",
    "    def return_labels(self):\n",
    "        return self._labels\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # contemplar posibilidad de triangulación\n",
    "        predictions = []\n",
    "        for row in X:\n",
    "            min_distance = math.inf\n",
    "            nearest_centroid = None\n",
    "            for centroid_label in range(self.n_clusters):\n",
    "                distance = dist(row, self._centroids[centroid_label])\n",
    "                # print(\"distancia entre\", row, \"y\", self._centroids[centroid_label], \"es: \", distance, \"con label\", centroid_label)\n",
    "                # print(\"distancia: \", distance, \"\\nmin_distancia: \", min_distance)\n",
    "                if distance < min_distance:\n",
    "                    # print(\"dentro if\")\n",
    "                    min_distance = distance\n",
    "                    nearest_centroid = centroid_label\n",
    "            predictions.append(nearest_centroid)\n",
    "        return predictions\n",
    "    \n",
    "    def _assign_centroids(self):\n",
    "        # utilizar el módulo random de numpy para asignar los centroides: check\n",
    "        # sólo para la primera iteración (asignación de centroides iniciales): check\n",
    "        # un centroide a la misma posición dato aleatoriamente \n",
    "        # con replace = false nos aseguramos de que no se repita el mismo valor para dos centroides diferentes,\n",
    "        # de forma que todos los centroides tomen coordenadas distintas\n",
    "        c_index = np.random.choice(list(range(0, len(self.X))), size = self.n_clusters, replace = False)\n",
    "        # print(c_index)\n",
    "        for i in c_index:\n",
    "            self._centroids.append(self.X[i])\n",
    "            # print(\"centroide \",i, \": \", self.X[i])\n",
    "        # print(self._centroids)\n",
    "        # asignar valores de los datos a los que equivalen esas posiciones en la tabla a los \"centroides\"        \n",
    "    \n",
    "    def _assign_labels(self):\n",
    "        # función para asignar los datos a un centroides\n",
    "        # linalg.norm -> normaliza los vectores, no calcula distancias como tal; no es lo que buscamos\n",
    "        self._inertia = []\n",
    "        self._labels = []\n",
    "        \n",
    "        # generación de la matriz\n",
    "        for i in range(len(self.X)):\n",
    "            self._inertia.append(self._compute_inertia(self.X[i]))\n",
    "            \n",
    "            # encasillamiento con labels de cada dato a su respectivo centroide \n",
    "            self._labels.append(np.argmin(self._inertia[i], axis = 0))\n",
    "        \n",
    "        \n",
    "    def _stop(self):\n",
    "        \"\"\" condición de parada del bucle de actualización de labels y centroides de función fit()\n",
    "        si devuelve False, no se cumple la condición de parada. \n",
    "        si devuelve True sí se cumple la condición de parada: se para la ejecución\"\"\"\n",
    "        # print(\"stop\")\n",
    "        \n",
    "        # condición de parada por iteraciones, asegurando que la primera ejecución siempre ocurre \n",
    "        # (en history no hay nada, para que no compare y de error)\n",
    "        if self.iter == self.max_iter: \n",
    "            return True\n",
    "        if self.iter == 0:\n",
    "            return False\n",
    "        \n",
    "        prev_centroids= self.history['centroids'][-1]\n",
    "        cambia = [False] * self.n_clusters\n",
    "        # print(self.history)\n",
    "        # print(\"centroides previos: \", prev_centroids)\n",
    "        # print(\"centroides actualizados: \", self._centroids)\n",
    "        for i in range (self.n_clusters):\n",
    "            #Si este centroide no cambia respecto del mismo en la anterior iteración, devolver True para este centroide\n",
    "            if np.array_equal(self._centroids[i], prev_centroids[i]):\n",
    "                # print(\"no ha cambiado el centroide \", i)\n",
    "                cambia[i] = True\n",
    "        #Si no hay diferencias, los centroides no han cambiado en la última iteración y se cumple la condición de parada.    \n",
    "        # Es decir, si todos son iguales\n",
    "        if False in cambia:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def _update_centroides(self):\n",
    "        # siguientes iteraciones para reposicionar los centroides\n",
    "    \n",
    "        for i in range(self.n_clusters):\n",
    "            control= []\n",
    "            for j in range(len(self.X)):\n",
    "                if self._labels[j]==i:\n",
    "                        control.append(self.X[j])\n",
    "            #print(\"control list:\", control)\n",
    "            #print(np.mean(control))\n",
    "            self._centroids[i]= np.mean(control, axis = 0)\n",
    "        # print(\"centroides actualizados\", self._centroids)\n",
    "    \n",
    "    def _compute_inertia(self, x):\n",
    "        \"\"\" distancia entre el dato o row 'x' y cada centroide' \"\"\"\n",
    "        distance_row=[]\n",
    "        \n",
    "        for centroid in self._centroids: \n",
    "            #print(x, centroid)\n",
    "            distance_row.append(dist(x,centroid))\n",
    "       \n",
    "        return distance_row\n",
    "        \n",
    "    def _add_history_step(self):\n",
    "        \"\"\" actualización de historial de centroides para nueva iteración \"\"\"\n",
    "        # self.history es un array de diccionarios, cada uno con toda esta información\n",
    "        self.history['iteration'].append(self.iter)\n",
    "        self.history['centroids'].append(self._centroids.copy())\n",
    "        self.history['labels'].append(self._labels.copy())\n",
    "        self.history['inertia'].append(self._inertia.copy())\n",
    "        \n",
    "        # print(\"history: \", self.history['centroids'][self.iter])\n",
    "        # print(\"centroides: \", self._centroids)\n",
    "        \n",
    "    def scatterplot_centroids(self):\n",
    "        \"\"\"creates a scatterplot with the final centroids\n",
    "        only valid for self.X with 2 dimensions\"\"\"\n",
    "        for i in range(self.n_clusters):\n",
    "             plt.scatter(self._centroids[i][0], self._centroids[i][1])\n",
    "    \n",
    "    \"\"\"\n",
    "    def scatterplot_all(self):\n",
    "        # actualmente este código funciona pero da muchísimos errores: revisar si se quiere incluir o se hará a mano\n",
    "        # creación de n colores aleatorios por n_clusters\n",
    "        \n",
    "        colors = []\n",
    "        for i in range(self.n_clusters):\n",
    "            r = random.randint(0, 255) / 255.0\n",
    "            g = random.randint(0, 255) / 255.0\n",
    "            b = random.randint(0, 255) / 255.0\n",
    "            colors.append((r, g, b))\n",
    "\n",
    "        # Crear una lista de colores para cada punto en los datos\n",
    "            for j in range(len(self.X)):\n",
    "                if self._labels[j] == i:\n",
    "                    plt.scatter(self.X[j][0], self.X[j][1], c=colors[i])\n",
    "    \"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kmeans = KMeans_Ours(n_clusters=3)\n",
    "result = kmeans.fit(x)\n",
    "kmeans.return_centroids()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"centroides finales: \", kmeans.return_centroids())\n",
    "print(\"número de iteraciones totales: \", kmeans.iter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"for i in range(3):\n",
    "     plt.scatter(cent[i][0], cent[i][1])\"\"\"\n",
    "kmeans.scatterplot_centroids()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# kmeans.scatterplot_all()\n",
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "for i in range(kmeans.n_clusters):\n",
    "    for j in range(len(x)):\n",
    "        if kmeans._labels[j] == i:\n",
    "            plt.scatter(x[j][0], x[j][1], c=colors[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dist(kmeans.predict(x), kmeans.return_labels())\n",
    "#print(len(kmeans.return_labels()), len(kmeans.predict(x)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# con estrellas\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stars = pd.read_csv('Stars2.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(stars.shape)\n",
    "len(stars)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "prueba: para ello necesitamos eliminar el color y la spectral class (sólo en este caso), en realidad: hacer Onehotencoding etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars_prueba = stars.drop(columns = [\"Color\", \"Spectral_Class\"])\n",
    "#stars.drop[\"Spectral_Class\"]\n",
    "stars_prueba"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# convert dataframe to array\n",
    "stars_prueba_array = stars_prueba.values\n",
    "stars_prueba_array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kmeans_stars_prueba = KMeans_Ours()\n",
    "result = kmeans_stars_prueba.fit(stars_prueba_array)\n",
    "print(kmeans_stars_prueba.return_centroids())\n",
    "print(kmeans_stars_prueba.iter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.scatter(stars_prueba_array[:, 0], stars_prueba_array[:, 1], stars_prueba_array[:, 2], stars_prueba_array[:, 3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "colors = [\"#FF9C34\", \"#4E9A06\", \"#DEB887\", \"#65B199\", \"#BDD4EE\", \"#3F567A\", \"#526AD5\", \"#00D542\"]\n",
    "for i in range(kmeans_stars_prueba.n_clusters):\n",
    "    for j in range(len(stars_prueba_array)):\n",
    "        if kmeans_stars_prueba._labels[j] == i:\n",
    "            # aquí hay que hacer lo de reducir a sólo dos dimensiones para poder hacer el scatterplot \n",
    "            # (sólo deja con dos dimensiones)\n",
    "            plt.scatter(stars_prueba_array[j][0], stars_prueba_array[j][1], c = colors[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# II. Preprocesado de Datos\n",
    "En esta sección se preprocesa el dataset proporcionado, aplicando procesamiento de features de tipo One-hot-encoding y codificación ordinal, así como transformación de la dimensionalidad de los datos mediante PCA. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stars = pd.read_csv('Stars2.csv')\n",
    "stars.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En primer lugar, observamos los diferentes colores asociados a las estrellas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars['Color'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver que algunos valores se repiten con ligeras diferencias en el nombre de la etiqueta. Por ejemplo, \"yellowish\" y \"Yellowish\" son la misma etiqueta pero con la primera letra escrita en minúscula y mayúscula respectivamente. Por lo tanto, modificamos los nombres de las etiquetas de color a minúsculas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars['Color'] = stars['Color'].str.lower()\n",
    "stars['Color'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "También observamos que \"blue-white\" es la misma etiqueta que \"blue white\", con la diferencia del guión que separa las dos palabras, que en el primer caso está presente y en el segundo no. Algo similar ocurre con \"yellow-white\" y \"white-yellow\". Asumimos en estos dos casos que el valor del atributo es el mismo, y para ello modificamos el nombre de las etiquetas para que ninguna tenga guión y proponemos el orden \"yellow white\" para todos los casos. Asumimos también que hay una diferencia entre \"yellowish white\" y \"yellow white\", igual que hay diferencia entre \"white\" y \"whitish\", por lo que estos dos valores del atributo \"Color\" se mantienen como diferentes valores."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars.loc[stars['Color']=='blue-white', 'Color'] = 'blue white'\n",
    "stars.loc[stars['Color']=='white-yellow', 'Color'] = 'yellow white'\n",
    "stars.loc[stars['Color']=='yellow-white', 'Color'] = 'yellow white'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars['Color'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars[stars['Color']=='blue white']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuación, se preprocesan los valores del atributo 'Spectral_Class' para asegurar que todos ellos son correctos, mediante un proceso similar al realizado para el atirbuto 'Color'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars['Spectral_Class'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es fácilmente observable que todos los valores son correctos, se corresponden con la escala de valores proporcionada en el enunciado de esta práctica, y no se repiten ni presentan errores de nombramiento de las etiquetas, por lo que no es necesario realizar modificaciones en este atributo del dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez se han preprocesado los atributos de la clase espectral y el color asociados a cada estrella de nuestro dataframe, se llevan a cabo dos técnicas para transformar los datos y poder trabajar con variables categóricas. \n",
    "\n",
    "En primer lugar, se llevará a cabo la técnica de \"One-Hot-Encoding\" de cada una de estas dos variables. A continuación, se llevará a cabo una transformación de las variables a atributos ordinales, de forma que se ordenan los colores según se atribuyan a mayor o menor temperatura, e igualmente para la variable de la clase espectral.\n",
    "\n",
    "Para poder comparar los resultados arrojados por una técnica y otra, generamos dos copias de nuestro dataframe según el tratamiento de los datos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars_1hot= stars.copy()\n",
    "stars_ordinal= stars.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. One Hot Encoding\n",
    "Se estudia la posibilidad de convertir las variables categóricas del dataset a vairables numéricas binarias mediante la técnica del One-Hot-Encoding, que genera una variable binaria para cada posible valor del atributo original."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#1. One Hot Encoding de color\n",
    "\n",
    "for color in stars_1hot['Color'].unique():\n",
    "    labels= []\n",
    "    #Iteramos 1 vez por fila\n",
    "    for i in stars_1hot['Color']:\n",
    "        if i==color:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    stars_1hot[color]= labels\n",
    "\n",
    "# se elimina el atributo inicial\n",
    "stars_1hot = stars_1hot.drop(columns=[\"Color\"])\n",
    "\n",
    "stars_1hot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#2. One hot encoding de Clase espectral\n",
    "for spectral in stars_1hot['Spectral_Class'].unique():\n",
    "    labels= []\n",
    "    #Iteramos 1 vez por fila\n",
    "    for i in stars_1hot['Spectral_Class']:\n",
    "        if i==spectral:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    stars_1hot[spectral]= labels\n",
    "\n",
    "# se elimina el atributo inicial\n",
    "stars_1hot = stars_1hot.drop(columns=[\"Spectral_Class\"])\n",
    "    \n",
    "stars_1hot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Ordinal Scale Encoding\n",
    "En esta segunda variante, convertimos las variables categóricas a escalas ordinales. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# orden de clase espectral asociada a una estrella de menor a mayor energía\n",
    "spectral_class=[\"M\",\"K\",\"G\",\"F\",\"A\",\"B\",\"O\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels= []\n",
    "\n",
    "#Iteramos 1 vez por fila\n",
    "for i in stars_ordinal['Spectral_Class']:\n",
    "    labels.append(spectral_class.index(i))\n",
    "       \n",
    "stars_ordinal['Spectral_Class']= labels\n",
    "    \n",
    "stars_ordinal\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En el caso de los colores, debemos averiguar en primer lugar el orden, es decir, qué colores se asignan a las estrellas menos calientes y cuáles a las más caliente. Para ello, se ha decidido ordenar los colores según la temperatura media de todas las estrellas asociadas a un mismo color. A continuación se obtiene dicho orden, de colores con menor temperatura media a aquellos con mayor temperatura media."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "color_means=[]\n",
    "\n",
    "iter = 0\n",
    "for color in stars_ordinal['Color'].unique():\n",
    "    \n",
    "    temp= stars_ordinal[stars_ordinal['Color']==color]['Temperature'].mean()\n",
    "    \n",
    "    # inserción del primer elemento\n",
    "    if iter == 0:\n",
    "        color_means.append({'Color': color, 'Temperature': temp})\n",
    "    \n",
    "    # inserción del resto, comprobando la posición de inserción\n",
    "    else:\n",
    "        inserted= False\n",
    "        i=0\n",
    "        while not inserted and i<len(color_means):\n",
    "            if temp <= color_means[i]['Temperature']:\n",
    "                color_means.insert(i, {'Color': color, 'Temperature': temp})\n",
    "                inserted = True\n",
    "            i+=1\n",
    "        \n",
    "        if not inserted:\n",
    "            color_means.append({'Color': color, 'Temperature': temp})\n",
    "            \n",
    "    iter += 1 \n",
    "    # print(\"array de medias actualizado: \", color_means)\n",
    "\n",
    "colors = []\n",
    "for i in range(len(color_means)):\n",
    "    colors.append(color_means[i]['Color'])\n",
    "print(\"Array of sorted colors\", colors)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En base a ello se procede a asignar la etiqueta ordinal correspondiente al color de cada estrella."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels= []\n",
    "\n",
    "#Iteramos 1 vez por fila\n",
    "for i in stars_ordinal['Color']:\n",
    "    labels.append(colors.index(i))\n",
    "\n",
    "stars_ordinal['Color']= labels\n",
    "    \n",
    "stars_ordinal\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.PCA\n",
    "Para poder aplicar el algoritmo de clasificación y poder representar los datos correctamente se aplica un algoritmo de PCA, Análisis de Componentes Principales. Esto es necesario para reducir la dimensionalidad y permitir la correcta visualización de los datos clusterizados, ya que actualmente están formados por más de dos dimensiones (las dimensiones son los atributos).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En primer lugar se debe llevar a cabo un nuevo preprocesamiento de los datos para escalar las variables."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#features = stars_1hot.columns.tolist()\n",
    "#features_ = stars_1hot[[features[0], features[1], features[2]]]\n",
    "\n",
    "# con el dataset preprocesado con ordinal scaler\n",
    "scaler = StandardScaler()\n",
    "stars_ordinal_scaled= scaler.fit_transform(stars_ordinal[['Temperature', 'L', 'R', 'A_M', 'Color', 'Spectral_Class']])\n",
    "stars_ordinal_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# con el dataset preprocesado con One Hot Encoding\n",
    "stars_1hot_scaled = scaler.fit_transform(stars_1hot[['Temperature', 'L', 'R', 'A_M', 'red', 'blue white', 'white',\n",
    "                                                    'yellowish white', 'pale yellow orange', 'blue', 'whitish', \n",
    "                                                    'yellow white', 'orange', 'yellowish', 'orange-red', 'M', 'B', \n",
    "                                                    'A', 'F', 'O', 'K', 'G']])\n",
    "stars_1hot_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "stars_ordinal_pca = pca.fit_transform(stars_ordinal_scaled)\n",
    "stars_ordinal_pca"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stars_1hot_pca = pca.fit_transform(stars_1hot_scaled)\n",
    "stars_1hot_pca"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III. Aplicación de Algoritmos de clustering "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. K-means\n",
    "### A. Selección de número de clusters - Método del Codo\n",
    "En primer lugar, es necesario escoger un número de clusters adecuado para especificar el hiperparámetro del modelo K-means. Para ello se emplea el método \"del codo\", que compara la inercia obtenida para un rango de posibles valores de n_clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def elbow_method(data, init= 2, final= 8):\n",
    "    \"\"\"Calcula los coeficientes del método del codo para el rango de enteros init-final\"\"\"\n",
    "    results= [] \n",
    "    for i in range(init, final+1): \n",
    "        kmeans = KMeans(n_clusters=i)  #Cada iteración se crea un número distinto de clústers.\n",
    "        kmeans.fit(data)\n",
    "        results.append(kmeans.inertia_)\n",
    "    #Impresión del gráfico\n",
    "    plt.plot(range(init, final +1 ), results)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "elbow_method(stars_1hot_pca)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "elbow_method(stars_ordinal_pca)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Intepretación de resultados\n",
    "Tras aplicar la función a ambos sets de datos, e pueden obsrvar ligeras difrencias en la gráfica obtenida. \n",
    "Para los datos tratados con one-hot-encoding, se observa una primera \"punta\" del codo para 3 clusters. A partir de aquí, comienza un descenso considerable de la variación marginal de la inercia, suavizando la curva para los valores más altos. \n",
    "Por otra parte, el codo obtenido para los datos ordinales presenta una curva menos marcada, con un extremo de codo entorno a los 4 o 5 clústers. \n",
    "Con esto en cuenta, se realizará una clusterización con 4 clústers para cada método, a fin de respetar los resultados obtenidos y facilitar la comparación entre ambos conjuntos de datos. También se realiza una segunda clasificación con 6 clústers en base a las categorías proporcionadas en el enunciado. Esta segunda ejecución permitirá evaluar los conjuntos obtenidos en el último apartado de la práctica. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B. Aplicación de k-means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def kmeans_clustering(data, n):\n",
    "    kmeans = KMeans(n_clusters=n)  # Número de clusters a crear\n",
    "    kmeans.fit(data)\n",
    "    results = {'labels': kmeans.labels_,\n",
    "              'centroids': kmeans.cluster_centers_}\n",
    "    return results\n",
    "\n",
    "# Resultados para 4 clústers\n",
    "km1hot_n4 = kmeans_clustering(stars_1hot_pca, 4)\n",
    "print(\"K-Means (One-Hot Encoding) with 4 clusters:\",np.bincount(km1hot_n4['labels']),\n",
    "      \"\\nCentroides: \", km1hot_n4['centroids'])\n",
    "\n",
    "kmord_n4 = kmeans_clustering(stars_ordinal_pca, 4)\n",
    "print(\"\\nK-Means (Ordinal) with 4 clusters:\", np.bincount(kmord_n4['labels']),\n",
    "      \"\\nCentroides: \", kmord_n4['centroids'])\n",
    "\n",
    "# Resultados para 6 clústers\n",
    "km1hot_n6 = kmeans_clustering(stars_1hot_pca, 6)\n",
    "print(\"\\nK-Means (One-Hot Encoding) with 6 clusters:\", np.bincount(km1hot_n6['labels']),\n",
    "      \"\\nCentroides: \", km1hot_n6['centroids'])\n",
    "\n",
    "kmord_n6 = kmeans_clustering(stars_ordinal_pca, 6)\n",
    "print(\"\\nK-Means (Ordinal) with 6 clusters:\", np.bincount(kmord_n6['labels']),\n",
    "      \"\\nCentroides: \", kmord_n6['centroids'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creación de una función para imprimir el scatterplot de los resultados de los algoritmos de clustering."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def clustering_plot(n_clusters, data, colors, results):\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(len(data)):\n",
    "            if results['labels'][j] == i:\n",
    "                plt.scatter(data[j][0], data[j][1], c=colors[i])\n",
    "    for centroid in results['centroids']:\n",
    "        plt.scatter(centroid[0], centroid[1], marker='*', s=100, c='black')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\",\"#8E44AD\", \"#FF6347\", \"#FFC0CB\" ]\n",
    "n_clusters_4 = 4\n",
    "n_clusters_6 = 6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#1-hot n4 clustering plot\n",
    "clustering_plot(n_clusters_4, stars_1hot_pca, colors, km1hot_n4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Ordinal n4 clustering plot\n",
    "clustering_plot(n_clusters_4, stars_ordinal_pca, colors, kmord_n4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#1-hot n6 clustering plot\n",
    "clustering_plot(n_clusters_6, stars_1hot_pca, colors, km1hot_n6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Ordinal n6 clustering plot\n",
    "clustering_plot(n_clusters_6, stars_ordinal_pca, colors, kmord_n6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discusión de resultados\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Clustering Jerárquico\n",
    "En este segundo método se emplea la técnica de clustering jerárquico para realizar la agrupación de los datos. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Algoritmo de Clustering Jerárquico\n",
    "def hierarchical_clustering(data, n= None, dist=0):\n",
    "    hierarchical = AgglomerativeClustering(distance_threshold=dist, n_clusters=n)  # Número de clusters a crear\n",
    "    return hierarchical.fit(data)\n",
    "def hierarchical_labels(data, n=None, dist=0):\n",
    "    hierarchical = AgglomerativeClustering(distance_threshold=dist, n_clusters=n)  # Número de clusters a crear\n",
    "    return hierarchical.fit(data).labels_\n",
    "\n",
    "\n",
    "model_hier_c1Hot= hierarchical_clustering(stars_1hot_pca)\n",
    "model_hier_ord=  hierarchical_clustering(stars_ordinal_pca)\n",
    "\n",
    "#print(\"Clustering Jerárquico (One-Hot Encoding) with 4 clusters:\", np.bincount(labels_hier_c1Hot))\n",
    "#print(\"Clustering Jerárquico (Ordinal Encoding) with 4 clusters:\", np.bincount(labels_hier_ord))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez entrenado un modelo general y definidas las funciones para obtener el modelo y las etiquetas generadas, se imprime un gráfico mostrando la jerarquía creada por el algoritmo. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Generación de dendograma -implementación por sklearn.\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_dendrogram(model_hier_c1Hot, truncate_mode=\"level\", p=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_dendrogram(model_hier_ord, truncate_mode=\"level\", p=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como se puede observar, y en concordancia con los resultados obtenidos para el algoritmo k-means, ejecutar el algoritmo con un número de clusters superior a 3 afina notablemente los resultados, proporcionando una clasificación mucho más precisa. \n",
    "A efectos de comparación con el método anterior se realizan las llamadas al método para 4 y 6 clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def clustering_hier_plot(n_clusters, data, colors, results):\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(len(data)):\n",
    "            if results[j] == i:\n",
    "                plt.scatter(data[j][0], data[j][1], c=colors[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_hier_1Hot_n4 = hierarchical_labels(stars_1hot_pca, n_clusters_4, None)\n",
    "\n",
    "#1hot n4 clustering plot\n",
    "clustering_hier_plot(n_clusters_4, stars_1hot_pca, colors, labels_hier_1Hot_n4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_hier_ord_n4= hierarchical_labels(stars_ordinal_pca, n_clusters_4, None)\n",
    "\n",
    "#Ordinal n4 clustering plot\n",
    "clustering_hier_plot(n_clusters_4, stars_ordinal_pca, colors, labels_hier_ord_n4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_hier_1Hot_n6= hierarchical_labels(stars_1hot_pca, 6, None)\n",
    "\n",
    "#1hot n6 clustering plot\n",
    "clustering_hier_plot(n_clusters_6, stars_1hot_pca, colors, labels_hier_1Hot_n6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_hier_ord_n6= hierarchical_labels(stars_ordinal_pca, 6, None)\n",
    "\n",
    "#Ordinal n6 clustering plot\n",
    "clustering_hier_plot(n_clusters_6, stars_ordinal_pca, colors, labels_hier_ord_n6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discusión de resultados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. DBA -Clustering por densidades\n",
    "Finalmente, se implementa un último método de clustering basado en densidades. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Algoritmo de DBSCAN\n",
    "def dbscan_clustering(data, eps= 0.5, min= 5):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min)  # Parámetros eps y min_samples\n",
    "    return dbscan.fit(data).labels_\n",
    "\n",
    "labels_dbscan_1hot = dbscan_clustering(stars_1hot_pca)\n",
    "labels_dbscan_ord = dbscan_clustering(stars_ordinal_pca)\n",
    "\n",
    "print(\"DBSCAN (One-Hot Encoding) dba :\", labels_dbscan_1hot)\n",
    "print(\"DBSCAN (Ordinal Encoding) dba :\", labels_dbscan_ord)\n",
    "\n",
    "#print(\"DBSCAN (Ordinal Encoding):\", np.bincount(labels_dbscan_ordinal))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dba_cluster_values_1hot= set(labels_dbscan_1hot)\n",
    "n_clusters_dba_1hot= len(dba_cluster_values_1hot)\n",
    "\n",
    "dba_cluster_values_ord= set(labels_dbscan_ord)\n",
    "n_clusters_dba_ord= len(dba_cluster_values_ord)\n",
    "\n",
    "print(\"1-hot clusters: \", n_clusters_dba_1hot, \"with values: \", dba_cluster_values_1hot, \"\\n\")\n",
    "print(\"ordinal clusters: \", n_clusters_dba_ord, \"with values: \", dba_cluster_values_ord, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.361650100Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "for i in range(kmeans.n_clusters):\n",
    "    for j in range(len(stars_1hot_pca)):\n",
    "        if labels_kmeans_1hot[j] == i:\n",
    "            plt.scatter(stars_1hot_pca[j][0], stars_1hot_pca[j][1], c=colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.369629200Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "for i in range(kmeans.n_clusters):\n",
    "    for j in range(len(stars_ordinal_pca)):\n",
    "        if labels_kmeans_1hot[j] == i:\n",
    "            plt.scatter(stars_ordinal_pca[j][0], stars_ordinal_pca[j][1], c=colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución de los datos es diferente porque el preprocesado también ha sido diferente, se ha llevado a cabo el algoritmo de PCA sobre datos tratados de manera distinta, y por lo tanto, sobre más dimensiones iniciales en el caso de los datos preprocesados con One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T08:06:50.680943800Z",
     "start_time": "2024-05-08T08:06:50.379569Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_ours = KMeans_Ours(n_clusters = 3)\n",
    "kmeans_ours.fit(stars_1hot_pca)\n",
    "kmeans_ours_1hot_labels = kmeans_ours.return_labels()\n",
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "for i in range(kmeans_ours.n_clusters):\n",
    "    for j in range(len(stars_1hot_pca)):\n",
    "        if kmeans_ours_1hot_labels[j] == i:\n",
    "            plt.scatter(stars_1hot_pca[j][0], stars_1hot_pca[j][1], c=colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.388585Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_ours = KMeans_Ours(n_clusters = 3)\n",
    "kmeans_ours.fit(stars_ordinal_pca)\n",
    "kmeans_ours_ordinal_labels = kmeans_ours.return_labels()\n",
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "for i in range(kmeans_ours.n_clusters):\n",
    "    for j in range(len(stars_ordinal_pca)):\n",
    "        if kmeans_ours_ordinal_labels[j] == i:\n",
    "            plt.scatter(stars_ordinal_pca[j][0], stars_ordinal_pca[j][1], c=colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la clasificación es idéntica, en los resultados los grupos son los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.398518200Z"
    }
   },
   "outputs": [],
   "source": [
    "import statistics as s\n",
    "hola = [1, 2, 3]\n",
    "s.mean(hola)\n",
    "array1 = np.array([1, 2, 3])\n",
    "array2 = np.array([4, 5, 6])\n",
    "todos = []\n",
    "todos.append(array1)\n",
    "todos.append(array2)\n",
    "print(todos)\n",
    "# Calcular la media de los dos arrays\n",
    "media_arrays = np.mean(todos, axis = 0)\n",
    "media_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.408528200Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "for i in range(kmeans.n_clusters):\n",
    "    for j in range(len(x)):\n",
    "        if kmeans._labels[j] == i:\n",
    "            plt.scatter(x[j][0], x[j][1], c=colors[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.443578700Z"
    }
   },
   "outputs": [],
   "source": [
    "print(hola)\n",
    "print(hola[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.444576800Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.random.choice(list(range(0, len(stars))), size = 5, replace = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.445606900Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.random.random(size = (100, 2))\n",
    "centroide = np.random.random_integers(0, len(X))\n",
    "centroide\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.447568300Z"
    }
   },
   "outputs": [],
   "source": [
    "centroids = []\n",
    "centroids = np.random.choice(range(0, len(X)), size = 8, replace = False)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.454548200Z"
    }
   },
   "outputs": [],
   "source": [
    "matriz = [1, 2, [3, 4], [5, 6]]\n",
    "print(matriz[0][2], matriz[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.460532300Z"
    }
   },
   "outputs": [],
   "source": [
    "matriz_distancias = []\n",
    "for i in range(len(X)):\n",
    "    matriz_distancias.append([])\n",
    "    for j in range(7):\n",
    "         matriz_distancias[i].append(np.random.randint(1, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.465524100Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_=[]\n",
    "for i in range(len(matriz_distancias)):\n",
    "    labels_.append(np.argmin(matriz_distancias[i], axis = 0))\n",
    "\n",
    "labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.471504500Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.randint(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.478520300Z"
    }
   },
   "outputs": [],
   "source": [
    "np.argmin(matriz_distancias, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.482507500Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn es una librería de código abierto, se puede ver cómo está implementado en Scikit learn, no copiar la misma solución, pero usarlo como inspiración. Hay un apartado de indicar similitud con scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "Algoritmo no supervisado muy útil, reduce la dimensionalidad de los datos (columnas). En lugar de eliminar columnas, existen métodos más interesantes que ese.\n",
    "Prdecir el número escrito en el gráfico en base a la luminosidad de los píxeles. Se ve bien con cmap = 'Greys'.\n",
    "\n",
    "Se usará el algoritmo PCA antes del algoritmo de clustering, y el de clustering se usará sobre las dos dimensiones que devuelve PCA (kmeans o lo que sea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.489493200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pylot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = load.digits().data\n",
    "X.shape\n",
    "plt.imshow(np.reshape(X[0], (8,8)))\n",
    "pca = PCA.fit(X)\n",
    "plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.494447100Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas fallidas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-08T08:06:50.499433900Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"self.history.centroids\n",
    "        \n",
    "        for i in range(self.n_clusters):\n",
    "            centroide = np.random.random_integers(0, len(self.X)-1, size=self.n_clusters)\n",
    "            \n",
    "            for c in centroide:\n",
    "                if centroide.count(c) == 1:\n",
    "                    self.history.centroids.append(X[c])\n",
    "                else:\n",
    "                    centroide[c] = np.random.random_integers(0, len(self.X)-1)\n",
    "                    while centroide\n",
    "            \n",
    "            duplicate = False\n",
    "            while self.history.centroids du\n",
    "            if i>0:\n",
    "                for i in range(len(self.history.centroids)):\n",
    "                    if centroide == self.history.centroids[i]:\n",
    "                        \n",
    "            self.history.centroids.append(np.)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
